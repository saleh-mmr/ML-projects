{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm4jzkwMbyjh"
      },
      "source": [
        "\n",
        "#**Classification with Decision Tree - hyperparameter tuning (__model selection__) with Grid Search and Cross Validation**\n",
        "\n",
        "\n",
        "---\n",
        "We use the Decision Tree algorithm to build a model for classification. To evaluate its performance, we apply standard CrossValidation, ensuring robustness. Finally, we optimize the model by finding the best hyperparameter setting through grid search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn_Fnk91WzZ2"
      },
      "source": [
        "Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIr261dceitF"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lIG_y9vXAVw"
      },
      "source": [
        "**Importing libraries for ML**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g8wCbMSbFT8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "minJxVJwXEOE"
      },
      "source": [
        "**Loading Data**\n",
        "\n",
        "\n",
        "> We start by preparing the environment for our machine learning workflow.\n",
        "This involves importing essential libraries, loading the dataset iris.csv,\n",
        "and defining parameters like training set size and random state for reproducibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a72fFosdWue"
      },
      "outputs": [],
      "source": [
        "names= ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
        "df = pd.read_csv(\"iris.csv\", sep=',', names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frg3KmB4WmsR"
      },
      "source": [
        "**Data exploration**\n",
        "\n",
        "\n",
        "> We explore the dataset to understand its structure and key statistics.\n",
        "The df.head() function displays the first few rows, while df.describe() provides summary statistics.\n",
        "df['class'].value_counts() shows the distribution of class labels, helping to assess class balance.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3WftOWaeP4d"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbZxE5XWeRTy"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVFzm4lIedHg"
      },
      "outputs": [],
      "source": [
        "df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "789RaliAlQA_"
      },
      "source": [
        "**Split the data into the train and test sets**\n",
        "\n",
        "\n",
        "\n",
        "> We split the dataset into X (features) and y (target labels) for training the model.\n",
        "Irrelevant columns, if any, are removed using the drop() method to improve model performance.\n",
        "The axis parameter in drop() determines whether rows (axis=0) or columns (axis=1) are removed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTHT0Nblk5be"
      },
      "outputs": [],
      "source": [
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FZjxYUe0Szj"
      },
      "outputs": [],
      "source": [
        "print(\"There are \"+ str(X_train.shape[0])+\" samples in training dataset\")\n",
        "print(\"Each sample has \"+ str(X_train.shape[1])+\" features\")\n",
        "print(\"There are \"+ str(X_test.shape[0])+\" samples in testing dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVT4iIrglh0v"
      },
      "source": [
        "\n",
        "**Constructoring a Model**\n",
        "> We train a DecisionTreeClassifier using the training data and make predictions on X_test.\n",
        "The model's performance is evaluated using accuracy_score,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvwbXy312sIx"
      },
      "outputs": [],
      "source": [
        "estimator = DecisionTreeClassifier(random_state=42)\n",
        "estimator.fit(X_train,y_train)\n",
        "y_predict = estimator.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_predict)\n",
        "maximum_depth = estimator.tree_.max_depth\n",
        "impurity = estimator.tree_.impurity[0]\n",
        "depth_values = [*range(1,maximum_depth+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj0Fass27OHy"
      },
      "outputs": [],
      "source": [
        "scores = ['accuracy', 'recall_macro', 'f1_macro', 'precision_macro']\n",
        "\n",
        "params = {'max_depth': depth_values,\n",
        "          'criterion': ['gini', 'entropy'],\n",
        "          'class_weight': ['balanced', None]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6p4A6cme7Z"
      },
      "source": [
        "**Loops on scores**\n",
        "\n",
        "\n",
        "\n",
        "> We iterate over different scoring functions to evaluate the model's performance.\n",
        "For each score, we train the estimator, identify the best model, and generate predictions.\n",
        "Finally, we print the best score, show the classification_report, and visualize the confusion matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk8SPPcM8E2F"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for score in scores:\n",
        "  clf = GridSearchCV(estimator=estimator,\n",
        "                       cv=skf,\n",
        "                       param_grid=params,\n",
        "                       scoring= score,\n",
        "                       return_train_score=False)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_predict = clf.predict(X_test)\n",
        "  cr = classification_report(y_true=y_test, y_pred=y_predict, target_names=y_test.unique().tolist())\n",
        "  cm = confusion_matrix(y_test, y_predict, labels=clf.classes_)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=clf.classes_)\n",
        "  disp.plot()\n",
        "  plt.title('Analyzing for scoring **' + str(score) + '**\\n' + 'Best params: ' + str(clf.best_params_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
