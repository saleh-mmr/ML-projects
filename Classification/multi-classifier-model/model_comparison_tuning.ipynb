{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Classifier Model Selection and Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n",
        "> This project explores multiple classification models and optimizes their hyperparameters using GridSearchCV from scikit-learn. Various classifiers are compared based on different scoring functions to identify the best-performing model. The process includes dataset preprocessing, model selection, hyperparameter tuning, and evaluation using classification metrics and confusion matrices. The results highlight the most effective classifiers for the given dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "9TegdlP62ts_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AD42z2gL2mAb"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing libraries for ML**\n",
        "\n",
        "\n",
        "> We start by preparing the environment for our machine learning workflow.\n",
        "This involves importing essential libraries, loading the dataset *churn-analysis.csv*,\n",
        "and defining parameters like training set size and random state for reproducibility.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qtJSl7-mVPpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV,StratifiedKFold,train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "a-x3SM9H3SEb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = 0.3\n",
        "random_state = 42\n",
        "n_splits = 3"
      ],
      "metadata": {
        "id": "kBtbbECq3kcv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('churn-analysis.csv', sep=',', header=0)"
      ],
      "metadata": {
        "id": "pKR2QCdg30VI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data exploration**\n",
        "\n",
        "\n",
        "> Using various methods to explore the dataset and display different aspects of its features.\n",
        "\n"
      ],
      "metadata": {
        "id": "UfOGS-KhWEd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "h3ujZYu94Ppg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "UXRHbKo-4RdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Exited'].value_counts()"
      ],
      "metadata": {
        "id": "Q7StNc1C4TMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(df['Age'])\n"
      ],
      "metadata": {
        "id": "96AObjYO5biW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the models**\n",
        "\n",
        "> This project defines multiple classification models, including Perceptron, KNN, Decision Tree, Random Forest, AdaBoost, and NaÃ¯ve Bayes. Each model is paired with a set of hyperparameters for optimization using GridSearchCV. The models are evaluated using various scoring metrics such as accuracy, F1-score, recall, and precision.\n",
        "\n"
      ],
      "metadata": {
        "id": "gF8pKfbEWzwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lbl = ['ln', 'KNN', 'dt', 'rf', 'adb', 'nb']\n",
        "\n",
        "models = {\n",
        "    'ln': {\n",
        "            'name': 'Linear Perceptron',\n",
        "            'estimator': Perceptron(random_state = random_state),\n",
        "            'param': {'class_weight': ['balanced', None], 'early_stopping': [True, False]}\n",
        "          },\n",
        "    'KNN': {\n",
        "            'name': 'K Nearest Neighbour',\n",
        "            'estimator': KNeighborsClassifier(),\n",
        "            'param': {'n_neighbors': [*range(5,11)], 'weights': ['uniform', 'distance']}\n",
        "           },\n",
        "    'dt': {\n",
        "            'name': 'Decision Tree',\n",
        "            'estimator': DecisionTreeClassifier(random_state=random_state),\n",
        "            'param': {'criterion': ['gini','entropy'], 'class_weight': ['balanced', None], 'max_depth': [*range(5,11)]}\n",
        "          },\n",
        "    'rf': {\n",
        "            'name': 'Random Forest',\n",
        "            'estimator': RandomForestClassifier(random_state=random_state),\n",
        "            'param': [{'max_depth': [*range(4,10)],'n_estimators':[*range(10,60,10)]}]          },\n",
        "    'adb': {\n",
        "            'name': 'AdaBoost',\n",
        "            'estimator': AdaBoostClassifier(random_state=random_state),\n",
        "            'param': {'n_estimators':[10,20,30,40,50], 'learning_rate':[0.2,0.5,0.75,1,1.25,1.5]}\n",
        "          },\n",
        "    'nb': {'name': 'Gaussian Naive Bayes',\n",
        "           'estimator': GaussianNB(),\n",
        "           'param': [{'var_smoothing': [10**exp for exp in range(-3,-13,-1)]}]\n",
        "          }\n",
        "\n",
        "}\n",
        "\n",
        "scoring = ['accuracy', 'f1_macro', 'recall_macro', 'precision_macro']"
      ],
      "metadata": {
        "id": "txtmgZS_521d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training and Evaluation Setup**\n",
        "\n",
        "\n",
        "> evaluation. A Stratified K-Fold cross-validator is used to ensure balanced class distribution across training folds. An empty results DataFrame is initialized to store performance metrics for different models after hyperparameter tuning.\n",
        "\n"
      ],
      "metadata": {
        "id": "ENqwP8GBXNpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, test_size=ts)"
      ],
      "metadata": {
        "id": "WWd-MiITFudy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
        "clfs = []\n",
        "results = pd.DataFrame(columns=['scoring',\n",
        "                                'model',\n",
        "                                'best_params',\n",
        "                                'accuracy',\n",
        "                                'precision_macro',\n",
        "                                'recall_macro',\n",
        "                                'f1_macro'])\n"
      ],
      "metadata": {
        "id": "nFsSK5BDG18W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning and Model Evaluation**\n",
        "\n",
        "\n",
        "\n",
        "> The code iterates over multiple scoring metrics and classifiers, applying Grid Search Cross-Validation to find the best hyperparameters. Each trained model is evaluated on the test set, and key performance metrics (accuracy, precision, recall, and F1-score) are stored in a results DataFrame. This process helps identify the most effective classifier and parameter combination for the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "frQX4idSXbxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for score in scoring:\n",
        "  for lbl in model_lbl:\n",
        "    clf = GridSearchCV(models[lbl]['estimator'], param_grid=models[lbl]['param'], scoring=score, cv=skf, return_train_score=False)\n",
        "    clf.fit(X_train,y_train)\n",
        "    clfs.append(clf)\n",
        "    y_predict = clf.predict(X_test)\n",
        "    cr = classification_report(y_test, y_predict, output_dict=True)\n",
        "    results.loc[len(results)] = [score, models[lbl]['name'],\n",
        "                                clf.best_params_,\n",
        "                                cr['accuracy'],\n",
        "                                cr['macro avg']['precision'],\n",
        "                                cr['macro avg']['recall'],\n",
        "                                cr['macro avg']['f1-score']\n",
        "                                ]"
      ],
      "metadata": {
        "id": "nY5HY5SzOFAs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying Model Performance**\n",
        "\n",
        "\n",
        "\n",
        "> Displaying evaluation results for each scoring metric, filtering the results DataFrame to show only models optimized for the current metric. The results are sorted in descending order based on the selected score, highlighting the top-performing models for each evaluation criterion.\n",
        "\n"
      ],
      "metadata": {
        "id": "HAGuw5aTXrLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for score in scoring:\n",
        "  print(\"Results for Scoring    **\"+str(score)+\"**\")\n",
        "  display(results[results['scoring'] == score].sort_values(by=[score], ascending=False).head())\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "7oQav5fgB7Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix for Best Models**\n",
        "\n",
        "> For each scoring metric, the best-performing model is identified by selecting the row with the highest score in the results DataFrame. The Confusion Matrix is then displayed for this model using ConfusionMatrixDisplay.from_estimator, providing a visual representation of classification performance. The plot title includes the scoring metric and the corresponding best model."
      ],
      "metadata": {
        "id": "QXgAxb4dX9SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for score in scoring:\n",
        "    best_row = results.loc[results.scoring==score,score].idxmax(axis=0)\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(X=X_test, y=y_test, estimator = clfs[best_row])\n",
        "    # disp.ax_.set_title(\"Best Model for {}: {}\".format(score,results.at[bests[score],'model']))\n",
        "    disp.ax_.set_title(\"Best Model for {}: {}\".format(score,results.at[best_row,'model']))"
      ],
      "metadata": {
        "id": "2lRonge4Kh7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}